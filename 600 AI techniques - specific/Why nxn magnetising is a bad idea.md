but that sounds like they just form pairs, whereas in fact many labels collect around just a few core labels . aha so this process is super unstable because there might be hundreds of the initial "clusters", none are interesting, and then we suddenly apply the number cutoff which almost arbitrarily makes a few of them super important?

It's interesting that if I look at the ones with the worst similarity in each cluster using kmeans they aren't too bad even at .3, 

Whereas with a worse clustering/labelling method this comparison can feel worse.

so the subjective experience of good or bad fit doesn't just depend on the actual similarity metric it's also feels better when the target label is a good label in some sense