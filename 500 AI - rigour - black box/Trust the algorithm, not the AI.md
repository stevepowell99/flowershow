
I often hear concerns about algorithms and AI, in everyday life as well as in evaluation, taking over our lives or making us submit to decisions made by machines. 

The worry about losing control to machines is real, but we need to distinguish between different cases, and in particular between **using algorithms to make decisions** and **using AI to make decisions**, especially **evaluative decisions**. This is particularly relevant in the field of evaluation.

**An algorithm** is simply a set of explicit steps to make a decision or produce an output, usually expressed in code or clear language. Organizations have used such rule-based systems for decades.
### No algorithm: trust the human

The alternative (precursor) to algorithms is trusting humans to make decisions. This can be great if humans consider context and individual circumstances, but it can also lead to bias and corruption.

We can see rubrics in evaluation (King et al., 2013) as a kind of soft algorithm. We usually welcome rubrics because they make evaluation criteria more explicit, transparent, and less subject to the whims and unreliability of individuals.

### Algorithms based on explicit criteria

Algorithms can help decide things like student admissions or loan approvals using clear steps (e.g., check age, if under 18 go to step 12, otherwise continue with step 5 ....). When implemented wisely, algorithms can improve fairness and consistency compared to human judgment alone.

### Algorithms with statistical formulas

Some algorithms use statistical models to predict outcomes, like creditworthiness, by combining data such as age or location. These models can become complex and harder to interpret, sometimes making their decisions seem arbitrary or unfair. The key difference is that with a more advanced statistical model we might find it increasingly hard to understand where the different parts of the formula come: it might combine parameters which for us seem meaningless and hard to justify but which have proven to be associated with the outcome of interest.

Both explicit and statistical algorithms can be criticized for bias, but they are transparent if their rules are published. Problems arise when rules are hidden or people are discriminated against because of the groups they belong to.

### Machine learning

In the extreme case we might have an algorithm based on machine learning (a form of AI, but not generative AI), where perhaps a neural network has been trained to distinguish desirable from undesirable candidates in just the same way you can train it to recognise a cat or distinguish a cat from a dog. Machine learning can be used to make decisions without clear formulas or rules. The process becomes a “black box,” where we input data and trust the output without understanding how the decision was made.

### Generative AI

The most extreme case is using generative AI for evaluative decisions without clear criteria ("big black box"): simply asking the AI, for example:
- is this program component effective?
- should this client get a loan?

## Conclusion: make good use of algorithms

People often misunderstand algorithms, which can provide explicit and transparent decision-making. The real concern is the shift toward statistical models, machine learning, and generative AI, where the decision-making process becomes less and less transparent. 

These are worrying not because they use algorithms but because they don't.
