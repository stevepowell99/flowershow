# Just add rigour: Three do’s and don’ts when using AI for text analysis.



![img](https://media.licdn.com/dms/image/v2/D4E12AQHEQQUb0CUeRQ/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1733398772936?e=1747872000&v=beta&t=frpYlU-deI1VMy5qXjZ4iDTdHReTlS0ew-psKBoJe34)



December 5, 2024

A lot of evaluation work is a kind of text analysis: processing reports, interview transcripts, etc. A bit like qualitative social science research. So this little piece is for evaluators in particular and (qualitative) social scientists in general.

How do we get from texts to evaluative judgements?

Recently many evaluators and researchers have been turning to AI to help.

BUT if you didn’t have a clear workflow from data to judgements *before* AI, don’t lean on the black box of the AI to cover that up. Here is my first set of Do’s and Don’ts. More next week.

### 1) DO Break up big, vague tasks into multiple smaller, clearer steps

![img](https://media.licdn.com/dms/image/v2/D4E12AQF1fmjwngMQLg/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1733398921207?e=1747872000&v=beta&t=tAApx9nCUzKa8vnKbZZtiyxohPpAHgWmzHk_gbCttpU)

[AIs excel at specific, well-defined tasks](https://www.qualiainterviews.com/documentation/general-tips-for-writing-prompts/) that can be verified intersubjectively, like rubrics. Most importantly they can answer lots of them, quickly.

“Intersubjectively verifiable” just means that most people will more or less agree on the answer most of the time.



- It creates transparency and allows others to verify your work.
- Clear instructions lead to more reliable results.
- If you can’t check it, you can’t trust it.



### Example of an intersubjectively verifiable task:

> ✅ Does this paragraph mention water and sanitation?

> ✅ If so, are any recent changes mentioned?

> ✅ If so, do these sound like positive changes according to the interviewee?

*Notice that here we’ve broken down a larger task into three smaller and simpler steps.*

### Examples of tasks which are not intersubjectively verifiable:

> ❌ Is the intervention described in this report efficient and effective?

*Text needs breaking up into sections, judgements on efficiency and effectiveness need breaking down into pieces, e.g. using rubrics.*

> ❌ What are the main themes in this document?

*This is a very common question in qualitative research, but it’s a terrible task to give to an AI without further details. What do we mean by a theme? Are we interested in economic aspects? Interpersonal aspects? How are the themes to be identified and refined? Here, a whole world of qualitative social science experience, skills and workflows (*[*grounded theory*](https://www.groundedtheoryonline.com/what-is-grounded-theory/)*,* [*thematic analysis*](https://www.tandfonline.com/doi/full/10.1080/17439760.2016.1262613)*) have been bypassed in a single sentence.*

> ❌ Summarise this document!

*Yes, everyone does it. Evaluators do it. Schoolchildren do it. Pets will be doing it soon. As a quick time-saver for low-stakes tasks, it’s very useful. But it’s the vaguest, highest-level instruction, not a systematic analysis.*

*How* do you break down a high-level judgement into a workflow of smaller tasks? Well isn’t that what evaluation methods and qualitative research methods are for? Go read a book!

We’re not saying you have to specify *in advance* exactly what methods you will use. That’s a bit too positivistic. But you should at least document them as you go along and be prepared to defend them when your analysis is done. That’s the untranslatable [Nachvollziehbarkeit](https://www.causalmap.app/resources/large-language-models-intersubjectivity/).

At Causal Map Ltd, we’ve found that [highlighting and then aggregating causal links](https://www.causalmap.app/resources/causal-mapping-for-evaluators/) is a great and relatively generic path from text data to the brink of evaluative judgement.

In terms of how to implement your workflow technically, see this [great contribution from Christopher Robert](https://www.linkedin.com/pulse/repeatable-reliable-transparent-graduating-from-ai-workflows-robert-nb4ge/?trackingId=mgVZuCtKQVCCnvH83DWOgA%3D%3D). At Causal Map, we’re also working on ways to make workflows accessible. See how we currently use AI in Causal Map [here](https://www.causalmap.app/ai/).

This post is based on my recent contribution to the [NLP-CoP](https://merltech.org/nlp-cop/) Ethics & Governance Working Group, along with colleagues [Niamh Barry](https://www.linkedin.com/in/niamh-barry-mel/), [Elizabeth Long](https://www.linkedin.com/in/elizabethannelong/) and [Grace Lyn Higdon](https://www.linkedin.com/in/gracelynhigdon/). In the next couple of weeks we’ll look at two more do’s and don’ts.
